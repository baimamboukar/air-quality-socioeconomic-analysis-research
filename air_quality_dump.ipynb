{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping GEE Maps Into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "import pprint as pp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project=\"ml-for-earth-observation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 416 sectors from shapefile\n",
      "Columns in the shapefile: ['Prov_ID', 'Province', 'Dist_ID', 'District', 'Sect_ID', 'Name', 'geometry']\n",
      "CRS information -->  PROJCS[\"TM_Rwanda\",GEOGCS[\"ITRF2005\",DATUM[\"International_Terrestrial_Reference_Frame_2005\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6896\"]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",30],PARAMETER[\"scale_factor\",0.9999],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",5000000],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 6000x6000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the date range for the last 12 months from current date\n",
    "now = datetime.datetime.now()\n",
    "end_date = ee.Date(now.strftime('%Y-%m-%d'))\n",
    "start_date = end_date.advance(-12, 'month')\n",
    "date_range = ee.DateRange(start_date, end_date)\n",
    "\n",
    "# Load Rwanda sector boundaries from shapefile\n",
    "sectors_gdf = gpd.read_file('rwa_sector/Sector.shp')\n",
    "\n",
    "# Print basic information about the sectors\n",
    "print(f\"Loaded {len(sectors_gdf)} sectors from shapefile\")\n",
    "print(\"Columns in the shapefile:\", sectors_gdf.columns.tolist())\n",
    "print(\"CRS information --> \", sectors_gdf.crs)\n",
    "\n",
    "# Plot the sectors to visualize them\n",
    "plt.figure(figsize=(10, 10), dpi=600)\n",
    "sectors_gdf.plot()\n",
    "plt.title('Rwanda Sectors')\n",
    "plt.savefig('rwanda_sectors_map.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sectors = ee.FeatureCollection(\"projects/ml-for-earth-observation/assets/rwa_sector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature collection created with 416 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"Feature collection created with {sectors.size().getInfo()} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection size: 5113 images\n",
      "Date range: 2024-03-14 to 2025-03-14\n",
      "\n",
      "Metadata for first image:\n",
      "Image ID: COPERNICUS/S5P/OFFL/L3_CH4/20240313T235522_20240315T155704\n",
      "Date: 2024-03-14\n",
      "\n",
      "Bands: ['CH4_column_volume_mixing_ratio_dry_air', 'aerosol_height', 'aerosol_optical_depth', 'sensor_azimuth_angle', 'sensor_zenith_angle', 'solar_azimuth_angle', 'solar_zenith_angle', 'CH4_column_volume_mixing_ratio_dry_air_bias_corrected', 'CH4_column_volume_mixing_ratio_dry_air_uncertainty']\n",
      "\n",
      "Value range:\n",
      "\n",
      "Creating a test visualization of the first image...\n",
      "Thumbnail URL (copy to browser to view): https://earthengine.googleapis.com/v1/projects/ml-for-earth-observation/thumbnails/1064b27c87e3e430e1c052d66ca15ae1-5069ebbc8c2598e5e4789974975f0f00:getPixels\n"
     ]
    }
   ],
   "source": [
    "# Load Sentinel-5P methane data\n",
    "collection = ee.ImageCollection('COPERNICUS/S5P/OFFL/L3_CH4')\\\n",
    "    .filterBounds(sectors) \\\n",
    "    .filterDate(date_range)\n",
    "\n",
    "# Print information about the collection\n",
    "print(f\"Collection size: {collection.size().getInfo()} images\")\n",
    "print(\n",
    "    f\"Date range: {start_date.format('YYYY-MM-dd').getInfo()} to {end_date.format('YYYY-MM-dd').getInfo()}\")\n",
    "\n",
    "# Get the first image to explore its properties\n",
    "if collection.size().getInfo() > 0:\n",
    "    first_image = collection.first()\n",
    "\n",
    "    # Get and print metadata\n",
    "    metadata = first_image.getInfo()\n",
    "    print(\"\\nMetadata for first image:\")\n",
    "    print(f\"Image ID: {metadata['id']}\")\n",
    "    print(\n",
    "        f\"Date: {ee.Date(metadata['properties']['system:time_start']).format('YYYY-MM-dd').getInfo()}\")\n",
    "\n",
    "    # Print band information\n",
    "    bands = first_image.bandNames().getInfo()\n",
    "    print(f\"\\nBands: {bands}\")\n",
    "\n",
    "    # Get statistics for the first image over our study area\n",
    "    stats = first_image.reduceRegion(\n",
    "        reducer=ee.Reducer.minMax(),\n",
    "        geometry=sectors.geometry().bounds(),\n",
    "        scale=1000,\n",
    "        maxPixels=1e9\n",
    "    ).getInfo()\n",
    "\n",
    "    print(\"\\nValue range:\")\n",
    "    for band in bands:\n",
    "        if band in stats:\n",
    "            print(\n",
    "                f\"{band}: Min = {stats[band+'_min']}, Max = {stats[band+'_max']}\")\n",
    "\n",
    "    # Create a test visualization\n",
    "    print(\"\\nCreating a test visualization of the first image...\")\n",
    "\n",
    "    # Define visualization parameters for methane\n",
    "    ch4_vis = {\n",
    "        'min': 1800,\n",
    "        'max': 1900,\n",
    "        'palette': ['blue', 'purple', 'cyan', 'green', 'yellow', 'red']\n",
    "    }\n",
    "\n",
    "    # Get a thumbnail URL (useful for checking if data is available)\n",
    "    thumbnail_url = first_image.getThumbURL({\n",
    "        'min': 1800,\n",
    "        'max': 1900,\n",
    "        'dimensions': 512,\n",
    "        'region': sectors.geometry().bounds()\n",
    "    })\n",
    "\n",
    "    print(f\"Thumbnail URL (copy to browser to view): {thumbnail_url}\")\n",
    "else:\n",
    "    print(\"No images found in the collection for the specified date range and area.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months to be processed:\n",
      "1. 2024-03: 2024-3\n",
      "2. 2024-04: 2024-4\n",
      "3. 2024-05: 2024-5\n",
      "4. 2024-06: 2024-6\n",
      "5. 2024-07: 2024-7\n",
      "6. 2024-08: 2024-8\n",
      "7. 2024-09: 2024-9\n",
      "8. 2024-10: 2024-10\n",
      "9. 2024-11: 2024-11\n",
      "10. 2024-12: 2024-12\n",
      "11. 2025-01: 2025-1\n",
      "12. 2025-02: 2025-2\n",
      "\n",
      "Monthly collection created with 12 images\n",
      "\n",
      "First monthly image metadata:\n",
      "Year: 2024\n",
      "Month: 3\n",
      "Date range: 2024-03-14 to 2024-04-14\n",
      "Image count: 432\n",
      "\n",
      "Mean CH4 for first month: {'CH4_column_volume_mixing_ratio_dry_air': 1891.1845122918835, 'CH4_column_volume_mixing_ratio_dry_air_bias_corrected': 1913.4830848777083, 'CH4_column_volume_mixing_ratio_dry_air_uncertainty': 4.0453995314221425, 'aerosol_height': 3000.196635699187, 'aerosol_optical_depth': 0.05228571711519492, 'sensor_azimuth_angle': -94.5410147702258, 'sensor_zenith_angle': 10.23788473846582, 'solar_azimuth_angle': -88.06377416882583, 'solar_zenith_angle': 22.035203121320563}\n"
     ]
    }
   ],
   "source": [
    "# Create a list of months to iterate over\n",
    "months = ee.List.sequence(0, 11).map(lambda n: ee.Dictionary({\n",
    "                                         'start': start_date.advance(n, 'month'),\n",
    "                                         'end': start_date.advance(n, 'month').advance(1, 'month'),\n",
    "                                         'year': start_date.advance(n, 'month').get('year'),\n",
    "                                         'month': start_date.advance(n, 'month').get('month')\n",
    "                                     })\n",
    "                                     )\n",
    "\n",
    "# Print the months we'll be processing\n",
    "print(\"Months to be processed:\")\n",
    "months_info = months.getInfo()\n",
    "for i, month in enumerate(months_info):\n",
    "    # Handle the date properly - it's already an EE Date in the dictionary\n",
    "    year = month['year']\n",
    "    month_num = month['month']\n",
    "    # Format the date directly from the year and month numbers\n",
    "    print(f\"{i+1}. {year}-{month_num:02d}: {year}-{month_num}\")\n",
    "\n",
    "# Function to calculate methane statistics for each month\n",
    "def process_month(month_obj):\n",
    "    month_obj = ee.Dictionary(month_obj)\n",
    "    month_start = ee.Date(month_obj.get('start'))\n",
    "    month_end = ee.Date(month_obj.get('end'))\n",
    "    year = month_obj.get('year')\n",
    "    month = month_obj.get('month')\n",
    "\n",
    "    # Get the mean methane concentration for this month\n",
    "    mean_image = collection.filterDate(month_start, month_end) \\\n",
    "        .mean() \\\n",
    "        .set({\n",
    "            'year': year,\n",
    "            'month': month,\n",
    "            'date_start': month_start.format('YYYY-MM-dd'),\n",
    "            'date_end': month_end.format('YYYY-MM-dd'),\n",
    "            'image_count': collection.filterDate(month_start, month_end).size()\n",
    "        })\n",
    "\n",
    "    return mean_image\n",
    "\n",
    "\n",
    "# Map the function over all months to create the monthly collection\n",
    "monthly_ch4 = ee.ImageCollection(months.map(process_month))\n",
    "\n",
    "# Print information about the monthly collection\n",
    "print(\n",
    "    f\"\\nMonthly collection created with {monthly_ch4.size().getInfo()} images\")\n",
    "\n",
    "# Test the first monthly image to verify the processing\n",
    "if monthly_ch4.size().getInfo() > 0:\n",
    "    first_monthly = monthly_ch4.first()\n",
    "    first_monthly_info = first_monthly.getInfo()\n",
    "\n",
    "    print(\"\\nFirst monthly image metadata:\")\n",
    "    if 'properties' in first_monthly_info:\n",
    "        props = first_monthly_info['properties']\n",
    "        print(f\"Year: {props.get('year')}\")\n",
    "        print(f\"Month: {props.get('month')}\")\n",
    "        print(\n",
    "            f\"Date range: {props.get('date_start', 'N/A')} to {props.get('date_end', 'N/A')}\")\n",
    "        print(f\"Image count: {props.get('image_count', 'N/A')}\")\n",
    "\n",
    "    # Get basic statistics for this monthly image\n",
    "    stats = first_monthly.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=sectors.geometry().bounds(),\n",
    "        scale=1000,\n",
    "        maxPixels=1e9\n",
    "    ).getInfo()\n",
    "\n",
    "    print(\"\\nMean CH4 for first month:\", stats)\n",
    "else:\n",
    "    print(\"No monthly images were created. Check if the original collection has data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results table created with 4992 records\n",
      "Error in enhance_result function: A mapped function's arguments cannot be used in client-side operations\n",
      "Error in enhance_result function: A mapped function's arguments cannot be used in client-side operations\n",
      "Error in enhance_result function: Unknown variable references: [_MAPPING_VAR_0_0].\n",
      "Enhanced results created with 4992 records\n",
      "\n",
      "Sample of tabulated results (first 5 records):\n",
      "\n",
      "Record 1:\n",
      "  Dist_ID: 11\n",
      "  District: Nyarugenge\n",
      "  Name: Gitega\n",
      "  Prov_ID: 1\n",
      "  Province: Kigali City\n",
      "  Sect_ID: 1101\n",
      "  date_end: 2024-04-14\n",
      "  date_start: 2024-03-14\n",
      "  image_count: 432\n",
      "  month: 3\n",
      "  year: 2024\n",
      "\n",
      "Record 2:\n",
      "  Dist_ID: 11\n",
      "  District: Nyarugenge\n",
      "  Name: Kanyinya\n",
      "  Prov_ID: 1\n",
      "  Province: Kigali City\n",
      "  Sect_ID: 1102\n",
      "  date_end: 2024-04-14\n",
      "  date_start: 2024-03-14\n",
      "  image_count: 432\n",
      "  month: 3\n",
      "  year: 2024\n",
      "\n",
      "Record 3:\n",
      "  Dist_ID: 11\n",
      "  District: Nyarugenge\n",
      "  Name: Kigali\n",
      "  Prov_ID: 1\n",
      "  Province: Kigali City\n",
      "  Sect_ID: 1103\n",
      "  date_end: 2024-04-14\n",
      "  date_start: 2024-03-14\n",
      "  image_count: 432\n",
      "  month: 3\n",
      "  year: 2024\n",
      "\n",
      "Record 4:\n",
      "  Dist_ID: 11\n",
      "  District: Nyarugenge\n",
      "  Name: Kimisagara\n",
      "  Prov_ID: 1\n",
      "  Province: Kigali City\n",
      "  Sect_ID: 1104\n",
      "  date_end: 2024-04-14\n",
      "  date_start: 2024-03-14\n",
      "  image_count: 432\n",
      "  month: 3\n",
      "  year: 2024\n",
      "\n",
      "Record 5:\n",
      "  Dist_ID: 11\n",
      "  District: Nyarugenge\n",
      "  Name: Mageregere\n",
      "  Prov_ID: 1\n",
      "  Province: Kigali City\n",
      "  Sect_ID: 1105\n",
      "  date_end: 2024-04-14\n",
      "  date_start: 2024-03-14\n",
      "  image_count: 432\n",
      "  month: 3\n",
      "  year: 2024\n",
      "\n",
      "Export task started: READY\n",
      "Task ID: ZFB6UP4WIKVSAUZUIRSACTZ7\n",
      "The export will include geometry information for each sector.\n",
      "You can map the data in GIS software using the center_lon and center_lat fields or the full geometry_json.\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate statistics for each sector\n",
    "def tabulate(image):\n",
    "    try:\n",
    "        # Use reduceRegions to get statistics for all sectors at once\n",
    "        reduced_regions = image.reduceRegions(\n",
    "            collection=sectors,\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            scale=1000,  # Balance between detail and performance\n",
    "            tileScale=4  # Help with computation timeouts\n",
    "        )\n",
    "\n",
    "        # Get the image metadata upfront to avoid repeated calls\n",
    "        year = image.get('year')\n",
    "        month = image.get('month')\n",
    "        date_start = image.get('date_start')\n",
    "        date_end = image.get('date_end')\n",
    "        image_count = image.get('image_count')\n",
    "\n",
    "        # Add image metadata to each feature\n",
    "        def add_metadata(feature):\n",
    "            return feature.set({\n",
    "                'year': year,\n",
    "                'month': month,\n",
    "                'date_start': date_start,\n",
    "                'date_end': date_end,\n",
    "                'image_count': image_count\n",
    "            })\n",
    "\n",
    "        return reduced_regions.map(add_metadata)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in tabulate function: {e}\")\n",
    "        # Return an empty feature collection if there's an error\n",
    "        return ee.FeatureCollection([])\n",
    "\n",
    "\n",
    "# Apply the function to each monthly image and flatten the results\n",
    "results_table = monthly_ch4.map(tabulate).flatten()\n",
    "\n",
    "# Print the size of the results table\n",
    "print(f\"Results table created with {results_table.size().getInfo()} records\")\n",
    "\n",
    "# Add additional useful fields\n",
    "\n",
    "\n",
    "def enhance_result(feature):\n",
    "    try:\n",
    "        # Format year-month as string\n",
    "        # Get the year and month as numbers\n",
    "        year_num = ee.Number(feature.get('year'))\n",
    "        month_num = ee.Number(feature.get('month'))\n",
    "\n",
    "        # Convert to strings and pad month with zero if needed\n",
    "        year_str = ee.String(year_num.format())\n",
    "        month_str = ee.String(month_num.format('%02d'))\n",
    "\n",
    "        # Concatenate them with a dash\n",
    "        year_month = year_str.cat('-').cat(month_str)\n",
    "\n",
    "        # Check if CH4 value exists\n",
    "        ch4_value = feature.get('CH4_column_volume_mixing_ratio_dry_air')\n",
    "        has_data = ee.Algorithms.If(\n",
    "            ee.Algorithms.IsEqual(ch4_value, None),\n",
    "            False,\n",
    "            True\n",
    "        )\n",
    "\n",
    "        # Handle different possible sector name properties\n",
    "        # Try common field names for sector names\n",
    "        sector_names = ['NAME', 'SECTOR_NAME', 'Name',\n",
    "                        'name', 'SECTOR', 'Sector', 'sector']\n",
    "\n",
    "        # Get the first available property that exists in the feature\n",
    "        sector_name = None\n",
    "        for name_field in sector_names:\n",
    "            if feature.propertyNames().contains(name_field).getInfo():\n",
    "                sector_name = feature.get(name_field)\n",
    "                break\n",
    "\n",
    "        # If none of the common names exist, use a default\n",
    "        if sector_name is None:\n",
    "            sector_name = ee.String(\"Sector_\").cat(\n",
    "                ee.String(feature.get('.geo')).slice(0, 8))\n",
    "\n",
    "        # Include geometry as a property for export\n",
    "        # Convert the geometry to a GeoJSON string\n",
    "        geometry_json = feature.geometry().toGeoJSONString()\n",
    "\n",
    "        # Include the center point coordinates for easier plotting\n",
    "        center_point = feature.geometry().centroid()\n",
    "        lon = center_point.coordinates().get(0)\n",
    "        lat = center_point.coordinates().get(1)\n",
    "\n",
    "        # Set all properties\n",
    "        return feature.set({\n",
    "            'year_month': year_month,\n",
    "            'has_data': has_data,\n",
    "            'sector_name': sector_name,\n",
    "            'geometry_json': geometry_json,\n",
    "            'center_lon': lon,\n",
    "            'center_lat': lat,\n",
    "            'date_processed': ee.Date(datetime.datetime.now().strftime('%Y-%m-%d')).format('YYYY-MM-dd')\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error in enhance_result function: {e}\")\n",
    "        # Return the original feature if there's an error\n",
    "        return feature\n",
    "\n",
    "\n",
    "# Apply the enhance_result function to each feature\n",
    "try:\n",
    "    enhanced_results = results_table.map(enhance_result)\n",
    "    print(\n",
    "        f\"Enhanced results created with {enhanced_results.size().getInfo()} records\")\n",
    "except Exception as e:\n",
    "    print(f\"Error enhancing results: {e}\")\n",
    "    enhanced_results = results_table\n",
    "    print(\"Using original results without enhancements\")\n",
    "\n",
    "# Print a sample of the results to verify\n",
    "try:\n",
    "    sample = enhanced_results.limit(5).getInfo()\n",
    "\n",
    "    print(\"\\nSample of tabulated results (first 5 records):\")\n",
    "    if 'features' in sample:\n",
    "        for i, feature in enumerate(sample['features']):\n",
    "            if i < 5:  # Limit to 5 entries\n",
    "                print(f\"\\nRecord {i+1}:\")\n",
    "                for key, value in feature['properties'].items():\n",
    "                    # Skip printing the full geometry JSON to keep output clean\n",
    "                    if key == 'geometry_json':\n",
    "                        print(f\"  {key}: [GeoJSON data]\")\n",
    "                        continue\n",
    "\n",
    "                    # Handle special formatting for certain fields\n",
    "                    if key.lower() in ['date_start', 'date_end', 'date_processed'] and value:\n",
    "                        try:\n",
    "                            # If it's a timestamp value, format it\n",
    "                            if isinstance(value, (int, float)) and value > 1000000000000:\n",
    "                                timestamp_ms = value\n",
    "                                date_str = datetime.datetime.fromtimestamp(\n",
    "                                    timestamp_ms/1000).strftime('%Y-%m-%d')\n",
    "                                print(f\"  {key}: {date_str}\")\n",
    "                            else:\n",
    "                                print(f\"  {key}: {value}\")\n",
    "                        except:\n",
    "                            print(f\"  {key}: {value}\")\n",
    "                    else:\n",
    "                        print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(\"No features found in the sample\")\n",
    "except Exception as e:\n",
    "    print(f\"Error getting sample: {e}\")\n",
    "\n",
    "# Export the results to Google Drive\n",
    "try:\n",
    "    # Include geometry and center point in selectors\n",
    "    selectors = [\n",
    "        'sector_name', 'year', 'month', 'year_month',\n",
    "        'CH4_column_volume_mixing_ratio_dry_air', 'has_data',\n",
    "        'date_start', 'date_end', 'image_count', 'date_processed',\n",
    "        'geometry_json', 'center_lon', 'center_lat'\n",
    "    ]\n",
    "\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=enhanced_results,\n",
    "        description='Rwanda_sectors_methane_last12months',\n",
    "        fileFormat='CSV',\n",
    "        folder='GEE_Exports',  # Specify a folder in your Google Drive\n",
    "        selectors=selectors\n",
    "    )\n",
    "\n",
    "    # Start the export task\n",
    "    task.start()\n",
    "\n",
    "    # Get task info\n",
    "    task_info = task.status()\n",
    "    print(f\"\\nExport task started: {task_info['state']}\")\n",
    "    print(f\"Task ID: {task.id}\")\n",
    "    print(f\"The export will include geometry information for each sector.\")\n",
    "    print(\"You can map the data in GIS software using the center_lon and center_lat fields or the full geometry_json.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error starting export task: {e}\")\n",
    "    print(\"Try exporting with fewer fields or a smaller dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-15 01:11:17,851 - AirQualityExtraction - INFO - AirQualityExtractor initialized\n",
      "2025-03-15 01:11:17,867 - AirQualityExtraction - INFO - Extracting data for all 7 pollutants\n",
      "2025-03-15 01:11:17,867 - AirQualityExtraction - INFO - Extracting UV Aerosol Index data\n",
      "2025-03-15 01:11:17,867 - AirQualityExtraction - INFO - Loading sectors from Earth Engine asset: projects/ml-for-earth-observation/assets/rwa_sector\n",
      "2025-03-15 01:11:18,476 - AirQualityExtraction - INFO - Loaded 416 sectors\n",
      "2025-03-15 01:11:19,826 - AirQualityExtraction - INFO - Sector properties: ['Dist_ID', 'District', 'Name', 'Prov_ID', 'Province', 'Sect_ID']\n",
      "2025-03-15 01:11:21,411 - AirQualityExtraction - INFO - Date range: 2025-01-15 to 2025-03-15\n",
      "2025-03-15 01:11:23,042 - AirQualityExtraction - INFO - Loaded 780 images for UV Aerosol Index\n",
      "2025-03-15 01:11:23,057 - AirQualityExtraction - INFO - Extracting band 'absorbing_aerosol_index' for UV Aerosol Index\n",
      "2025-03-15 01:11:23,066 - AirQualityExtraction - ERROR - Error extracting UV_AEROSOL: module 'ee' has no attribute 'Boolean'\n",
      "2025-03-15 01:11:23,066 - AirQualityExtraction - INFO - Extracting Carbon Monoxide data\n",
      "2025-03-15 01:11:25,258 - AirQualityExtraction - INFO - Date range: 2025-01-15 to 2025-03-15\n",
      "2025-03-15 01:11:26,158 - AirQualityExtraction - INFO - Loaded 778 images for Carbon Monoxide\n",
      "2025-03-15 01:11:26,178 - AirQualityExtraction - INFO - Extracting band 'CO_column_number_density' for Carbon Monoxide\n",
      "2025-03-15 01:11:26,180 - AirQualityExtraction - ERROR - Error extracting CO: module 'ee' has no attribute 'Boolean'\n",
      "2025-03-15 01:11:26,188 - AirQualityExtraction - INFO - Extracting Formaldehyde data\n",
      "2025-03-15 01:11:27,490 - AirQualityExtraction - INFO - Date range: 2025-01-15 to 2025-03-15\n",
      "2025-03-15 01:11:28,506 - AirQualityExtraction - INFO - Loaded 777 images for Formaldehyde\n",
      "2025-03-15 01:11:28,518 - AirQualityExtraction - INFO - Extracting band 'tropospheric_HCHO_column_number_density' for Formaldehyde\n",
      "2025-03-15 01:11:28,523 - AirQualityExtraction - ERROR - Error extracting HCHO: module 'ee' has no attribute 'Boolean'\n",
      "2025-03-15 01:11:28,526 - AirQualityExtraction - INFO - Extracting Nitrogen Dioxide data\n",
      "2025-03-15 01:11:29,803 - AirQualityExtraction - INFO - Date range: 2025-01-15 to 2025-03-15\n",
      "2025-03-15 01:11:30,923 - AirQualityExtraction - INFO - Loaded 685 images for Nitrogen Dioxide\n",
      "2025-03-15 01:11:30,937 - AirQualityExtraction - INFO - Extracting band 'tropospheric_NO2_column_number_density' for Nitrogen Dioxide\n",
      "2025-03-15 01:11:30,937 - AirQualityExtraction - ERROR - Error extracting NO2: module 'ee' has no attribute 'Boolean'\n",
      "2025-03-15 01:11:30,947 - AirQualityExtraction - INFO - Extracting Ozone data\n",
      "2025-03-15 01:11:32,018 - AirQualityExtraction - INFO - Date range: 2025-01-15 to 2025-03-15\n",
      "2025-03-15 01:11:33,021 - AirQualityExtraction - INFO - Loaded 772 images for Ozone\n",
      "2025-03-15 01:11:33,042 - AirQualityExtraction - INFO - Extracting band 'O3_column_number_density' for Ozone\n",
      "2025-03-15 01:11:33,050 - AirQualityExtraction - ERROR - Error extracting O3: module 'ee' has no attribute 'Boolean'\n",
      "2025-03-15 01:11:33,052 - AirQualityExtraction - INFO - Extracting Sulphur Dioxide data\n",
      "2025-03-15 01:11:34,866 - AirQualityExtraction - INFO - Date range: 2025-01-15 to 2025-03-15\n",
      "2025-03-15 01:11:35,689 - AirQualityExtraction - INFO - Loaded 772 images for Sulphur Dioxide\n",
      "2025-03-15 01:11:35,706 - AirQualityExtraction - INFO - Extracting band 'SO2_column_number_density' for Sulphur Dioxide\n",
      "2025-03-15 01:11:35,716 - AirQualityExtraction - ERROR - Error extracting SO2: module 'ee' has no attribute 'Boolean'\n",
      "2025-03-15 01:11:35,718 - AirQualityExtraction - INFO - Extracting Methane data\n",
      "2025-03-15 01:11:37,825 - AirQualityExtraction - INFO - Date range: 2025-01-15 to 2025-03-15\n",
      "2025-03-15 01:11:38,974 - AirQualityExtraction - INFO - Loaded 774 images for Methane\n",
      "2025-03-15 01:11:38,989 - AirQualityExtraction - INFO - Extracting band 'CH4_column_volume_mixing_ratio_dry_air' for Methane\n",
      "2025-03-15 01:11:38,989 - AirQualityExtraction - ERROR - Error extracting CH4: module 'ee' has no attribute 'Boolean'\n",
      "2025-03-15 01:11:39,005 - AirQualityExtraction - INFO - Exported task list to rwanda_air_quality\\export_tasks.json\n",
      "2025-03-15 01:11:39,013 - AirQualityExtraction - INFO - Exported task list to rwanda_air_quality\\export_tasks.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pollutant: UV_AEROSOL\n",
      "  Error: module 'ee' has no attribute 'Boolean'\n",
      "\n",
      "Pollutant: CO\n",
      "  Error: module 'ee' has no attribute 'Boolean'\n",
      "\n",
      "Pollutant: HCHO\n",
      "  Error: module 'ee' has no attribute 'Boolean'\n",
      "\n",
      "Pollutant: NO2\n",
      "  Error: module 'ee' has no attribute 'Boolean'\n",
      "\n",
      "Pollutant: O3\n",
      "  Error: module 'ee' has no attribute 'Boolean'\n",
      "\n",
      "Pollutant: SO2\n",
      "  Error: module 'ee' has no attribute 'Boolean'\n",
      "\n",
      "Pollutant: CH4\n",
      "  Error: module 'ee' has no attribute 'Boolean'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Air Quality Data Extraction for Rwanda Sectors\n",
    "===============================================\n",
    "\n",
    "This script extracts multiple air pollutant metrics from Sentinel-5P satellite data\n",
    "for all sectors in Rwanda, to support research on the relationship between\n",
    "air quality and socioeconomic status.\n",
    "\n",
    "Pollutants extracted:\n",
    "- Aerosol Index (UV)\n",
    "- Carbon Monoxide (CO)\n",
    "- Formaldehyde (HCHO)\n",
    "- Nitrogen Dioxide (NO2)\n",
    "- Ozone (O3)\n",
    "- Sulphur Dioxide (SO2)\n",
    "- Methane (CH4)\n",
    "\n",
    "Authors: [Your Team Names]\n",
    "Date: March 2025\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"air_quality_extraction.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger('AirQualityExtraction')\n",
    "\n",
    "# Initialize Earth Engine\n",
    "ee.Initialize()\n",
    "\n",
    "class AirQualityExtractor:\n",
    "    \"\"\"Class for extracting air quality data from Sentinel-5P for Rwanda sectors\"\"\"\n",
    "    \n",
    "    # Define pollutant collections and their bands of interest\n",
    "    POLLUTANT_CONFIG = {\n",
    "        'UV_AEROSOL': {\n",
    "            'collection': 'COPERNICUS/S5P/OFFL/L3_AER_AI',\n",
    "            'band': 'absorbing_aerosol_index',\n",
    "            'display_name': 'UV Aerosol Index',\n",
    "            'unit': 'index',\n",
    "            'scale_factor': 1  # No scaling needed\n",
    "        },\n",
    "        'CO': {\n",
    "            'collection': 'COPERNICUS/S5P/OFFL/L3_CO',\n",
    "            'band': 'CO_column_number_density',\n",
    "            'display_name': 'Carbon Monoxide',\n",
    "            'unit': 'mol/m^2',\n",
    "            'scale_factor': 1e5  # Scale by 1e5 to make values more readable\n",
    "        },\n",
    "        'HCHO': {\n",
    "            'collection': 'COPERNICUS/S5P/OFFL/L3_HCHO',\n",
    "            'band': 'tropospheric_HCHO_column_number_density',\n",
    "            'display_name': 'Formaldehyde',\n",
    "            'unit': 'mol/m^2',\n",
    "            'scale_factor': 1e5  # Scale by 1e5 to make values more readable\n",
    "        },\n",
    "        'NO2': {\n",
    "            'collection': 'COPERNICUS/S5P/OFFL/L3_NO2',\n",
    "            'band': 'tropospheric_NO2_column_number_density',\n",
    "            'display_name': 'Nitrogen Dioxide',\n",
    "            'unit': 'mol/m^2',\n",
    "            'scale_factor': 1e5  # Scale by 1e5 to make values more readable\n",
    "        },\n",
    "        'O3': {\n",
    "            'collection': 'COPERNICUS/S5P/OFFL/L3_O3',\n",
    "            'band': 'O3_column_number_density',\n",
    "            'display_name': 'Ozone',\n",
    "            'unit': 'mol/m^2',\n",
    "            'scale_factor': 1e2  # Scale by 100 to make values more readable\n",
    "        },\n",
    "        'SO2': {\n",
    "            'collection': 'COPERNICUS/S5P/OFFL/L3_SO2',\n",
    "            'band': 'SO2_column_number_density',\n",
    "            'display_name': 'Sulphur Dioxide',\n",
    "            'unit': 'mol/m^2',\n",
    "            'scale_factor': 1e5  # Scale by 1e5 to make values more readable\n",
    "        },\n",
    "        'CH4': {\n",
    "            'collection': 'COPERNICUS/S5P/OFFL/L3_CH4',\n",
    "            'band': 'CH4_column_volume_mixing_ratio_dry_air',\n",
    "            'display_name': 'Methane',\n",
    "            'unit': 'ppb',\n",
    "            'scale_factor': 1  # No scaling needed\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def __init__(self, shapefile_path=None, ee_asset_id=None, output_dir='output', sector_name_field='NAME'):\n",
    "        \"\"\"\n",
    "        Initialize the extractor.\n",
    "        \n",
    "        Args:\n",
    "            shapefile_path (str, optional): Path to Rwanda sectors shapefile.\n",
    "            ee_asset_id (str, optional): Earth Engine asset ID for Rwanda sectors.\n",
    "            output_dir (str): Directory to save output files.\n",
    "            sector_name_field (str): The field in the shapefile that contains sector names.\n",
    "        \n",
    "        Note:\n",
    "            Either shapefile_path or ee_asset_id must be provided.\n",
    "        \"\"\"\n",
    "        if shapefile_path is None and ee_asset_id is None:\n",
    "            raise ValueError(\"Either shapefile_path or ee_asset_id must be provided\")\n",
    "        \n",
    "        self.shapefile_path = shapefile_path\n",
    "        self.ee_asset_id = ee_asset_id\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.sector_name_field = sector_name_field\n",
    "        \n",
    "        # Will be populated in load_sectors\n",
    "        self.sectors = None\n",
    "        self.sectors_gdf = None\n",
    "        \n",
    "        # Dataset references for cleaning up\n",
    "        self.task_list = []\n",
    "        \n",
    "        logger.info(\"AirQualityExtractor initialized\")\n",
    "    \n",
    "    def load_sectors(self):\n",
    "        \"\"\"Load Rwanda sectors from either shapefile or EE asset\"\"\"\n",
    "        if self.sectors is not None:\n",
    "            return self.sectors\n",
    "        \n",
    "        if self.shapefile_path is not None:\n",
    "            try:\n",
    "                # Load from shapefile\n",
    "                logger.info(f\"Loading sectors from shapefile: {self.shapefile_path}\")\n",
    "                self.sectors_gdf = gpd.read_file(self.shapefile_path)\n",
    "                \n",
    "                # Save the CRS for reference\n",
    "                self.crs = self.sectors_gdf.crs\n",
    "                \n",
    "                # Check if it has necessary columns\n",
    "                logger.info(f\"Shapefile columns: {self.sectors_gdf.columns.tolist()}\")\n",
    "                \n",
    "                # Convert to GeoJSON for EE\n",
    "                geojson_path = self.output_dir / 'rwanda_sectors.geojson'\n",
    "                self.sectors_gdf.to_file(geojson_path, driver='GeoJSON')\n",
    "                \n",
    "                # Load into Earth Engine\n",
    "                self.sectors = ee.FeatureCollection(str(geojson_path))\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error loading shapefile: {e}\")\n",
    "                raise\n",
    "        else:\n",
    "            # Load from Earth Engine asset\n",
    "            logger.info(f\"Loading sectors from Earth Engine asset: {self.ee_asset_id}\")\n",
    "            self.sectors = ee.FeatureCollection(self.ee_asset_id)\n",
    "        \n",
    "        # Check and report the number of sectors\n",
    "        sectors_count = self.sectors.size().getInfo()\n",
    "        logger.info(f\"Loaded {sectors_count} sectors\")\n",
    "        \n",
    "        # Get sector property names for reference\n",
    "        if sectors_count > 0:\n",
    "            first_sector = self.sectors.first().getInfo()\n",
    "            if 'properties' in first_sector:\n",
    "                logger.info(f\"Sector properties: {list(first_sector['properties'].keys())}\")\n",
    "                \n",
    "                # Check if sector_name_field exists\n",
    "                if self.sector_name_field not in first_sector['properties']:\n",
    "                    logger.warning(f\"Sector name field '{self.sector_name_field}' not found in sector properties\")\n",
    "                    possible_name_fields = [col for col in first_sector['properties'].keys() \n",
    "                                          if any(name in col.upper() for name in ['NAME', 'SECTOR', 'ID'])]\n",
    "                    if possible_name_fields:\n",
    "                        self.sector_name_field = possible_name_fields[0]\n",
    "                        logger.info(f\"Using '{self.sector_name_field}' as sector name field instead\")\n",
    "                    else:\n",
    "                        logger.warning(\"No suitable sector name field found. Will use ID as fallback.\")\n",
    "        \n",
    "        return self.sectors\n",
    "    \n",
    "    def define_date_range(self, months=12, end_date=None):\n",
    "        \"\"\"\n",
    "        Define the date range for data extraction.\n",
    "        \n",
    "        Args:\n",
    "            months (int): Number of months to go back from end_date.\n",
    "            end_date (datetime, optional): End date, defaults to current date.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (start_date, end_date) as ee.Date objects\n",
    "        \"\"\"\n",
    "        if end_date is None:\n",
    "            end_date = datetime.datetime.now()\n",
    "        \n",
    "        end_date_ee = ee.Date(end_date.strftime('%Y-%m-%d'))\n",
    "        start_date_ee = end_date_ee.advance(-months, 'month')\n",
    "        \n",
    "        logger.info(f\"Date range: {start_date_ee.format('YYYY-MM-dd').getInfo()} to {end_date_ee.format('YYYY-MM-dd').getInfo()}\")\n",
    "        \n",
    "        return (start_date_ee, end_date_ee)\n",
    "    \n",
    "    def create_monthly_sequence(self, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Create a sequence of months for processing.\n",
    "        \n",
    "        Args:\n",
    "            start_date (ee.Date): Start date\n",
    "            end_date (ee.Date): End date\n",
    "            \n",
    "        Returns:\n",
    "            ee.List: List of dictionaries with month information\n",
    "        \"\"\"\n",
    "        # Get the difference in months\n",
    "        months_diff = ee.Number(end_date.difference(start_date, 'month')).round().int()\n",
    "        \n",
    "        # Create a sequence of months\n",
    "        months = ee.List.sequence(0, months_diff).map(lambda n:\n",
    "            ee.Dictionary({\n",
    "                'start': start_date.advance(n, 'month'),\n",
    "                'end': start_date.advance(n, 'month').advance(1, 'month'),\n",
    "                'year': start_date.advance(n, 'month').get('year'),\n",
    "                'month': start_date.advance(n, 'month').get('month')\n",
    "            })\n",
    "        )\n",
    "        \n",
    "        return months\n",
    "    \n",
    "    def load_pollutant_collection(self, pollutant_key, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Load a specific pollutant collection from Sentinel-5P.\n",
    "        \n",
    "        Args:\n",
    "            pollutant_key (str): Key from POLLUTANT_CONFIG\n",
    "            start_date (ee.Date): Start date\n",
    "            end_date (ee.Date): End date\n",
    "            \n",
    "        Returns:\n",
    "            ee.ImageCollection: Filtered collection for the pollutant\n",
    "        \"\"\"\n",
    "        if pollutant_key not in self.POLLUTANT_CONFIG:\n",
    "            raise ValueError(f\"Unknown pollutant key: {pollutant_key}\")\n",
    "        \n",
    "        config = self.POLLUTANT_CONFIG[pollutant_key]\n",
    "        \n",
    "        # Load and filter the collection\n",
    "        collection = ee.ImageCollection(config['collection']) \\\n",
    "            .select(config['band']) \\\n",
    "            .filterBounds(self.sectors) \\\n",
    "            .filterDate(start_date, end_date)\n",
    "        \n",
    "        # Check if we have data\n",
    "        size = collection.size().getInfo()\n",
    "        logger.info(f\"Loaded {size} images for {config['display_name']}\")\n",
    "        \n",
    "        if size == 0:\n",
    "            logger.warning(f\"No data found for {config['display_name']} in the specified date range\")\n",
    "        \n",
    "        return collection\n",
    "    \n",
    "    def process_monthly_data(self, collection, months, pollutant_key):\n",
    "        \"\"\"\n",
    "        Process a collection into monthly averages.\n",
    "        \n",
    "        Args:\n",
    "            collection (ee.ImageCollection): Pollutant collection\n",
    "            months (ee.List): List of month dictionaries\n",
    "            pollutant_key (str): Key from POLLUTANT_CONFIG\n",
    "            \n",
    "        Returns:\n",
    "            ee.ImageCollection: Collection of monthly average images\n",
    "        \"\"\"\n",
    "        config = self.POLLUTANT_CONFIG[pollutant_key]\n",
    "        band = config['band']\n",
    "        \n",
    "        def process_month(month_obj):\n",
    "            month_obj = ee.Dictionary(month_obj)\n",
    "            month_start = ee.Date(month_obj.get('start'))\n",
    "            month_end = ee.Date(month_obj.get('end'))\n",
    "            year = month_obj.get('year')\n",
    "            month = month_obj.get('month')\n",
    "            \n",
    "            # Filter the collection to this month\n",
    "            monthly_images = collection.filterDate(month_start, month_end)\n",
    "            \n",
    "            # Get the count of images for this month\n",
    "            image_count = monthly_images.size()\n",
    "            \n",
    "            # Calculate the mean if we have images\n",
    "            mean_image = ee.Algorithms.If(\n",
    "                image_count.gt(0),\n",
    "                monthly_images.mean().set({\n",
    "                    'year': year,\n",
    "                    'month': month,\n",
    "                    'date_start': month_start.format('YYYY-MM-dd'),\n",
    "                    'date_end': month_end.format('YYYY-MM-dd'),\n",
    "                    'image_count': image_count,\n",
    "                    'pollutant': pollutant_key,\n",
    "                    'band': band,\n",
    "                    'unit': config['unit'],\n",
    "                    'scale_factor': config['scale_factor']\n",
    "                }),\n",
    "                # Create an empty image with -9999 as placeholder for no data\n",
    "                ee.Image(ee.Array([[-9999]]))\n",
    "                    .rename([band])\n",
    "                    .set({\n",
    "                        'year': year,\n",
    "                        'month': month,\n",
    "                        'date_start': month_start.format('YYYY-MM-dd'),\n",
    "                        'date_end': month_end.format('YYYY-MM-dd'),\n",
    "                        'image_count': 0,\n",
    "                        'pollutant': pollutant_key,\n",
    "                        'band': band,\n",
    "                        'unit': config['unit'],\n",
    "                        'scale_factor': config['scale_factor'],\n",
    "                        'no_data': True\n",
    "                    })\n",
    "            )\n",
    "            \n",
    "            return ee.Image(mean_image)\n",
    "        \n",
    "        # Map the processing function over all months\n",
    "        monthly_collection = ee.ImageCollection(\n",
    "            months.map(process_month)\n",
    "        )\n",
    "        \n",
    "        return monthly_collection\n",
    "    \n",
    "    def extract_sector_data(self, monthly_collection, pollutant_key):\n",
    "        \"\"\"\n",
    "        Extract pollutant data for each sector from monthly averages.\n",
    "        \n",
    "        Args:\n",
    "            monthly_collection (ee.ImageCollection): Monthly average images\n",
    "            pollutant_key (str): Key from POLLUTANT_CONFIG\n",
    "            \n",
    "        Returns:\n",
    "            ee.FeatureCollection: Table with sector-level pollutant data\n",
    "        \"\"\"\n",
    "        config = self.POLLUTANT_CONFIG[pollutant_key]\n",
    "        band = config['band']\n",
    "        scale_factor = config['scale_factor']\n",
    "        \n",
    "        # Print the band name we're extracting to debug\n",
    "        logger.info(f\"Extracting band '{band}' for {config['display_name']}\")\n",
    "        \n",
    "        def tabulate(image):\n",
    "            # Check if the image has data (not marked as no_data)\n",
    "            has_no_data = ee.Algorithms.If(\n",
    "                image.propertyNames().contains('no_data'),\n",
    "                image.get('no_data'),\n",
    "                ee.Boolean(False)\n",
    "            )\n",
    "            \n",
    "            def process_with_data():\n",
    "                # Get important image properties only once to avoid repeated server calls\n",
    "                year = ee.Number(image.get('year'))\n",
    "                month = ee.Number(image.get('month'))\n",
    "                image_count = ee.Number(image.get('image_count'))\n",
    "                date_start = ee.String(image.get('date_start'))\n",
    "                date_end = ee.String(image.get('date_end'))\n",
    "                \n",
    "                # Scale the image values for better readability\n",
    "                scaled_image = image.multiply(scale_factor)\n",
    "                \n",
    "                # Reduce the image over each sector\n",
    "                reduced_regions = scaled_image.reduceRegions(\n",
    "                    collection=self.sectors,\n",
    "                    reducer=ee.Reducer.mean(),\n",
    "                    scale=1000,  # 1km scale\n",
    "                    tileScale=4  # Prevent computation timeouts\n",
    "                )\n",
    "                \n",
    "                # Add image metadata to each feature\n",
    "                def add_metadata(feature):\n",
    "                    # Format year-month for easier analysis\n",
    "                    year_month = ee.String(year.format()).cat('-').cat(ee.String(month.format('%02d')))\n",
    "                    \n",
    "                    # Get sector name from the feature using sector_name_field\n",
    "                    sector_name = feature.get(self.sector_name_field)\n",
    "                    \n",
    "                    # If sector_name_field doesn't exist, try some common alternatives\n",
    "                    sector_name = ee.Algorithms.If(\n",
    "                        ee.Algorithms.IsEqual(sector_name, None),\n",
    "                        self.get_fallback_sector_name(feature),\n",
    "                        sector_name\n",
    "                    )\n",
    "                    \n",
    "                    # Start with a clean set of properties\n",
    "                    return ee.Feature(feature.geometry(), {\n",
    "                        'sector_name': sector_name,\n",
    "                        'year': year,\n",
    "                        'month': month,\n",
    "                        'year_month': year_month,\n",
    "                        'date_start': date_start,\n",
    "                        'date_end': date_end,\n",
    "                        'image_count': image_count,\n",
    "                        'pollutant': pollutant_key,\n",
    "                        'unit': config['unit'],\n",
    "                        # Get the band value from the feature, this is the key operation\n",
    "                        band: feature.get(band),\n",
    "                        # Store center coordinates for mapping\n",
    "                        'center_lon': feature.geometry().centroid().coordinates().get(0),\n",
    "                        'center_lat': feature.geometry().centroid().coordinates().get(1),\n",
    "                        'date_processed': ee.Date(datetime.datetime.now().strftime('%Y-%m-%d')).format('YYYY-MM-dd')\n",
    "                    })\n",
    "                \n",
    "                return reduced_regions.map(add_metadata)\n",
    "            \n",
    "            def process_without_data():\n",
    "                # Create empty features with null values for the pollutant\n",
    "                def create_empty_feature(feature):\n",
    "                    # Get sector name from the feature using sector_name_field\n",
    "                    sector_name = feature.get(self.sector_name_field)\n",
    "                    \n",
    "                    # If sector_name_field doesn't exist, try some common alternatives\n",
    "                    sector_name = ee.Algorithms.If(\n",
    "                        ee.Algorithms.IsEqual(sector_name, None),\n",
    "                        self.get_fallback_sector_name(feature),\n",
    "                        sector_name\n",
    "                    )\n",
    "                    \n",
    "                    # Format year-month for easier analysis\n",
    "                    year = ee.Number(image.get('year'))\n",
    "                    month = ee.Number(image.get('month'))\n",
    "                    year_month = ee.String(year.format()).cat('-').cat(ee.String(month.format('%02d')))\n",
    "                    \n",
    "                    # Create a feature with complete metadata but null band value\n",
    "                    properties = {\n",
    "                        'sector_name': sector_name,\n",
    "                        'year': year,\n",
    "                        'month': month,\n",
    "                        'year_month': year_month,\n",
    "                        'date_start': image.get('date_start'),\n",
    "                        'date_end': image.get('date_end'),\n",
    "                        'image_count': 0,\n",
    "                        'pollutant': pollutant_key,\n",
    "                        'unit': config['unit'],\n",
    "                        band: None,  # Null value for no data\n",
    "                        'center_lon': feature.geometry().centroid().coordinates().get(0),\n",
    "                        'center_lat': feature.geometry().centroid().coordinates().get(1),\n",
    "                        'date_processed': ee.Date(datetime.datetime.now().strftime('%Y-%m-%d')).format('YYYY-MM-dd')\n",
    "                    }\n",
    "                    \n",
    "                    return ee.Feature(feature.geometry(), properties)\n",
    "                \n",
    "                return self.sectors.map(create_empty_feature)\n",
    "            \n",
    "            # Use the appropriate processing function based on whether we have data\n",
    "            return ee.FeatureCollection(\n",
    "                ee.Algorithms.If(\n",
    "                    has_no_data,\n",
    "                    process_without_data(),\n",
    "                    process_with_data()\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Map the tabulate function over all monthly images and flatten\n",
    "        results_table = monthly_collection.map(tabulate).flatten()\n",
    "        \n",
    "        return results_table\n",
    "    \n",
    "    def get_fallback_sector_name(self, feature):\n",
    "        \"\"\"\n",
    "        Try several common field names to find a suitable sector name.\n",
    "        \n",
    "        Args:\n",
    "            feature (ee.Feature): Feature to extract name from\n",
    "            \n",
    "        Returns:\n",
    "            ee.String: Sector name or a fallback generated from geometry ID\n",
    "        \"\"\"\n",
    "        # Common field names for sector names\n",
    "        name_fields = ['NAME', 'Name', 'name', 'SECTOR_NAME', 'SectorName', \n",
    "                       'SECTOR', 'Sector', 'sector', 'DIST_NAME', 'District',\n",
    "                       'ID', 'id', 'OBJECTID', 'FID']\n",
    "        \n",
    "        # Function to check if a field exists and return its value\n",
    "        def check_field(field):\n",
    "            return ee.Algorithms.If(\n",
    "                feature.propertyNames().contains(field),\n",
    "                feature.get(field),\n",
    "                None\n",
    "            )\n",
    "        \n",
    "        # Try each field in order\n",
    "        result = None\n",
    "        for field in name_fields:\n",
    "            # Skip the sector_name_field we already tried\n",
    "            if field == self.sector_name_field:\n",
    "                continue\n",
    "                \n",
    "            value = check_field(field)\n",
    "            result = ee.Algorithms.If(\n",
    "                ee.Algorithms.IsEqual(result, None),\n",
    "                ee.Algorithms.If(\n",
    "                    ee.Algorithms.IsEqual(value, None),\n",
    "                    result,\n",
    "                    value\n",
    "                ),\n",
    "                result\n",
    "            )\n",
    "        \n",
    "        # If no suitable field found, create a fallback using ID\n",
    "        return ee.Algorithms.If(\n",
    "            ee.Algorithms.IsEqual(result, None),\n",
    "            ee.String(\"Sector_\").cat(ee.String(feature.id()).slice(0, 8)),\n",
    "            result\n",
    "        )\n",
    "    \n",
    "    def export_results(self, results_table, pollutant_key):\n",
    "        \"\"\"\n",
    "        Export results to Google Drive.\n",
    "        \n",
    "        Args:\n",
    "            results_table (ee.FeatureCollection): Table with sector-level pollutant data\n",
    "            pollutant_key (str): Key from POLLUTANT_CONFIG\n",
    "            \n",
    "        Returns:\n",
    "            ee.batch.Task: Export task\n",
    "        \"\"\"\n",
    "        config = self.POLLUTANT_CONFIG[pollutant_key]\n",
    "        \n",
    "        # Define field selectors\n",
    "        band_name = config['band']\n",
    "        selectors = [\n",
    "            'sector_name', 'year', 'month', 'year_month', \n",
    "            band_name, 'image_count', 'pollutant', 'unit',\n",
    "            'date_start', 'date_end', 'date_processed',\n",
    "            'center_lon', 'center_lat'\n",
    "        ]\n",
    "        \n",
    "        # Create descriptive filename with timestamp\n",
    "        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        description = f\"Rwanda_sectors_{pollutant_key.lower()}_{timestamp}\"\n",
    "        \n",
    "        # Start export task\n",
    "        task = ee.batch.Export.table.toDrive(\n",
    "            collection=results_table,\n",
    "            description=description,\n",
    "            fileFormat='CSV',\n",
    "            folder='Rwanda_AirQuality',\n",
    "            selectors=selectors\n",
    "        )\n",
    "        \n",
    "        task.start()\n",
    "        task_id = task.id\n",
    "        logger.info(f\"Started export task for {config['display_name']}: {task_id}\")\n",
    "        \n",
    "        # Store task reference\n",
    "        self.task_list.append({\n",
    "            'task_id': task_id,\n",
    "            'pollutant': pollutant_key,\n",
    "            'description': description,\n",
    "            'time_started': datetime.datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        return task\n",
    "    \n",
    "    def export_task_list(self):\n",
    "        \"\"\"Export the list of tasks to a JSON file for reference\"\"\"\n",
    "        task_file = self.output_dir / 'export_tasks.json'\n",
    "        \n",
    "        # Update task status before exporting\n",
    "        updated_tasks = []\n",
    "        for task_info in self.task_list:\n",
    "            task_id = task_info['task_id']\n",
    "            try:\n",
    "                # Get all tasks as a Python list\n",
    "                all_tasks = list(ee.batch.Task.list())\n",
    "                \n",
    "                # Find our task by ID\n",
    "                matching_task = None\n",
    "                for t in all_tasks:\n",
    "                    if hasattr(t, 'id') and t.id == task_id:\n",
    "                        matching_task = t\n",
    "                        break\n",
    "                \n",
    "                # Update status if found\n",
    "                if matching_task:\n",
    "                    status = matching_task.status()\n",
    "                    task_info['status'] = {\n",
    "                        'state': status.get('state', 'UNKNOWN'),\n",
    "                        'creation_timestamp_ms': status.get('creation_timestamp_ms', 0),\n",
    "                        'update_timestamp_ms': status.get('update_timestamp_ms', 0),\n",
    "                        'description': status.get('description', '')\n",
    "                    }\n",
    "                else:\n",
    "                    task_info['status'] = {'state': 'NOT_FOUND'}\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error getting status for task {task_id}: {e}\")\n",
    "                task_info['status'] = {'state': 'ERROR', 'error': str(e)}\n",
    "            \n",
    "            updated_tasks.append(task_info)\n",
    "        \n",
    "        # Save to file\n",
    "        with open(task_file, 'w') as f:\n",
    "            json.dump(updated_tasks, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Exported task list to {task_file}\")\n",
    "        \n",
    "        logger.info(f\"Exported task list to {task_file}\")\n",
    "    \n",
    "    def extract_pollutant(self, pollutant_key, months=12, end_date=None):\n",
    "        \"\"\"\n",
    "        Extract a specific pollutant for all sectors over the specified time period.\n",
    "        \n",
    "        Args:\n",
    "            pollutant_key (str): Key from POLLUTANT_CONFIG\n",
    "            months (int): Number of months to go back from end_date\n",
    "            end_date (datetime, optional): End date, defaults to current date\n",
    "            \n",
    "        Returns:\n",
    "            dict: Information about the export task\n",
    "        \"\"\"\n",
    "        logger.info(f\"Extracting {self.POLLUTANT_CONFIG[pollutant_key]['display_name']} data\")\n",
    "        \n",
    "        # Ensure sectors are loaded\n",
    "        self.load_sectors()\n",
    "        \n",
    "        # Define date range\n",
    "        start_date, end_date = self.define_date_range(months, end_date)\n",
    "        \n",
    "        # Create monthly sequence\n",
    "        months_sequence = self.create_monthly_sequence(start_date, end_date)\n",
    "        \n",
    "        # Load pollutant collection\n",
    "        collection = self.load_pollutant_collection(pollutant_key, start_date, end_date)\n",
    "        \n",
    "        # Process monthly data\n",
    "        monthly_collection = self.process_monthly_data(collection, months_sequence, pollutant_key)\n",
    "        \n",
    "        # Extract sector-level data\n",
    "        results_table = self.extract_sector_data(monthly_collection, pollutant_key)\n",
    "        \n",
    "        # Export results\n",
    "        task = self.export_results(results_table, pollutant_key)\n",
    "        \n",
    "        # Return information about the task\n",
    "        return {\n",
    "            'pollutant': pollutant_key,\n",
    "            'task_id': task.id,\n",
    "            'start_date': start_date.format('YYYY-MM-dd').getInfo(),\n",
    "            'end_date': end_date.format('YYYY-MM-dd').getInfo()\n",
    "        }\n",
    "    \n",
    "    def extract_all_pollutants(self, months=12, end_date=None):\n",
    "        \"\"\"\n",
    "        Extract all configured pollutants for all sectors.\n",
    "        \n",
    "        Args:\n",
    "            months (int): Number of months to go back from end_date\n",
    "            end_date (datetime, optional): End date, defaults to current date\n",
    "            \n",
    "        Returns:\n",
    "            list: Information about all export tasks\n",
    "        \"\"\"\n",
    "        logger.info(f\"Extracting data for all {len(self.POLLUTANT_CONFIG)} pollutants\")\n",
    "        \n",
    "        # Extract each pollutant\n",
    "        results = []\n",
    "        for pollutant_key in self.POLLUTANT_CONFIG:\n",
    "            try:\n",
    "                result = self.extract_pollutant(pollutant_key, months, end_date)\n",
    "                results.append(result)\n",
    "                \n",
    "                # Add a small delay to avoid rate limiting\n",
    "                time.sleep(2)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error extracting {pollutant_key}: {e}\")\n",
    "                results.append({\n",
    "                    'pollutant': pollutant_key,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "        \n",
    "        # Export task list for future reference\n",
    "        self.export_task_list()\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Either specify a shapefile path\n",
    "    # SHAPEFILE_PATH = \"path/to/rwanda_sectors.shp\"\n",
    "    \n",
    "    # Or use an Earth Engine asset ID\n",
    "    EE_ASSET_ID = \"projects/ml-for-earth-observation/assets/rwa_sector\"\n",
    "    \n",
    "    # Create the extractor\n",
    "    # Specify the field that contains sector names - adjust if needed\n",
    "    extractor = AirQualityExtractor(\n",
    "        ee_asset_id=EE_ASSET_ID,\n",
    "        output_dir=\"rwanda_air_quality\",\n",
    "        sector_name_field=\"Name\"  # Change to match your actual field name\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Extract all pollutants for the last 2 months (less data for testing)\n",
    "        results = extractor.extract_all_pollutants(months=2)\n",
    "        \n",
    "        # Print task information\n",
    "        for result in results:\n",
    "            print(f\"Pollutant: {result['pollutant']}\")\n",
    "            if 'task_id' in result:\n",
    "                print(f\"  Task ID: {result['task_id']}\")\n",
    "                print(f\"  Date range: {result['start_date']} to {result['end_date']}\")\n",
    "            else:\n",
    "                print(f\"  Error: {result.get('error', 'Unknown error')}\")\n",
    "            print()\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"Error extracting data: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge the datasets\n",
    "import pandas as pd\n",
    "# Load the datasets\n",
    "poverty_df = pd.read_csv('clean_data_poverty.csv')\n",
    "poverty_with_index_df = pd.read_csv('data_with_poverty_index.csv')\n",
    "air_quality = pd.read_csv('rwanda_air_quality_2020_2025.csv')\n",
    "to_add = ['poor_percent', 'avg_deprivation_intensity', 'poverty_index']\n",
    "\n",
    "for add in to_add:\n",
    "    poverty_df[add] = poverty_with_index_df[add]\n",
    "    air_quality[add] = poverty_with_index_df[add]\n",
    "    \n",
    "# save the merged dataset\n",
    "poverty_df.to_csv('final_dataset.csv', index=False)\n",
    "air_quality.to_csv('final_air_quality.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
